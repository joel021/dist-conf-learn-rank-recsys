{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-10T12:55:14.793594Z",
     "start_time": "2025-08-10T12:55:14.778915Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "from recsysconfident.utils.files import sort_paths_by_datetime\n",
    "\n",
    "def find_subfolders_with_prefix(root_folder: str, prefix: str):\n",
    "\n",
    "  subfolders = []\n",
    "  for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "    for dirname in dirnames:\n",
    "      if dirname.startswith(prefix):\n",
    "        subfolders.append(os.path.join(dirpath, dirname))\n",
    "  return subfolders\n",
    "\n",
    "def read_json(path: str) -> dict:\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def generate_latex_table_from_dataframe(df: pd.DataFrame, caption: str, label: str, columns: list):\n",
    "\n",
    "    df = df[~df.index.str.contains(\"std\")]\n",
    "    std_columns = []\n",
    "    columns1 = []\n",
    "    for col in list(df.columns):\n",
    "        if \"std\" in col:\n",
    "            std_columns.append(col)\n",
    "        else:\n",
    "            columns1.append(col)\n",
    "\n",
    "    if not columns:\n",
    "        columns = columns1\n",
    "\n",
    "    for col in columns + std_columns:\n",
    "        df.loc[:, col] = df[col].astype(float).round(4)\n",
    "\n",
    "    df_bolded = df.astype(str)\n",
    "    for idx, row in df[columns].iterrows():\n",
    "\n",
    "        if \"rmse\" in idx or \"mae\" in idx:\n",
    "            bold_value = row.min()\n",
    "        else:\n",
    "            bold_value = row.max()\n",
    "\n",
    "        for col in columns:\n",
    "            if row[col] == bold_value:\n",
    "                df_bolded.at[idx, col] = \"\\\\textbf{\"+str(row[col])+\"}\"\n",
    "\n",
    "    for std_col in std_columns:\n",
    "        col_name = std_col[:-4]\n",
    "        formatted_col = df_bolded[col_name].astype(str) + \" $ \\\\pm $ \" + df_bolded[std_col].astype(str)\n",
    "        df_bolded[col_name] = formatted_col\n",
    "\n",
    "    df_bolded = df_bolded[columns]\n",
    "    df_bolded = df_bolded.reset_index().rename(columns={'index': 'metric'})\n",
    "\n",
    "    latex_code = df_bolded.to_latex(\n",
    "        label=label,\n",
    "        caption=caption,\n",
    "        index=False,\n",
    "        escape=False,  # Prevent escaping special characters\n",
    "        column_format=\"c\" * len(df.columns)  # Center align columns\n",
    "    )\n",
    "    return latex_code\n",
    "\n",
    "def get_models_metrics(dataset_uris) -> pd.DataFrame:\n",
    "\n",
    "    models_metrics_dfs = {}\n",
    "    for path in dataset_uris:\n",
    "        if \"data_splits\" in path:\n",
    "            continue\n",
    "\n",
    "        setup = read_json(sort_paths_by_datetime(glob.glob(f\"{path}/setup-*.json\"))[-1])\n",
    "        model_name = setup['model_name']\n",
    "\n",
    "        metrics_list = sort_paths_by_datetime(glob.glob(f\"{path}/metrics-*.json\"))\n",
    "        metrics_df = pd.DataFrame.from_dict([read_json(metrics_list[-1])[split_name]])\n",
    "\n",
    "        if model_name in models_metrics_dfs:\n",
    "            models_metrics_dfs[model_name] = pd.concat([models_metrics_dfs[model_name], metrics_df], axis=0)\n",
    "        else:\n",
    "            models_metrics_dfs[model_name] = metrics_df\n",
    "    return models_metrics_dfs\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T12:55:14.827873Z",
     "start_time": "2025-08-10T12:55:14.806356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#group_name = \"proposal\"\n",
    "#columns = ['cpgat', 'mf-not-reg', 'gnn', 'gnn-mf']\n",
    "group_name = \"learn-rank\"\n",
    "columns = ['learn-rank-cpgatbpr', 'learn-rank-cpmfbpr', 'learn-rank-dgatbpr','learn-rank-mf', 'learn-rank-att-cluster']\n",
    "\n",
    "split_name = \"test\"\n",
    "\n",
    "datasets_uris = {\n",
    "  \"amazon-beauty\": find_subfolders_with_prefix(f\"../runs/{group_name}/\", \"amazon-beauty\"),\n",
    "  \"jester-joke\": find_subfolders_with_prefix(f\"../runs/{group_name}/\", \"jester-joke\"),\n",
    "  \"ml-1m\": find_subfolders_with_prefix(f\"../runs/{group_name}/\", \"ml-1m\"),\n",
    "    \"rotten-tomatoes\": find_subfolders_with_prefix(f\"../runs/{group_name}/\", \"rotten-tomatoes\")\n",
    "}"
   ],
   "id": "bb8439244cb6111f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T12:55:15.094467Z",
     "start_time": "2025-08-10T12:55:14.863445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics_ds = {}\n",
    "for dataset_name in datasets_uris.keys():\n",
    "\n",
    "    models_metrics_dfs_dict = get_models_metrics(datasets_uris[dataset_name])\n",
    "\n",
    "    for model_name in models_metrics_dfs_dict.keys():\n",
    "\n",
    "        mean_metrics_df = models_metrics_dfs_dict[model_name].astype(float).mean()\n",
    "        mean_metrics_df = mean_metrics_df.to_frame(name=model_name) #index: metrics names, columns: [mean]\n",
    "\n",
    "        std_metrics_df = models_metrics_dfs_dict[model_name].astype(float).std()\n",
    "        std_metrics_df = std_metrics_df.to_frame(name=f'{model_name}_std')\n",
    "\n",
    "        if dataset_name in metrics_ds:\n",
    "            metrics_ds[dataset_name] = pd.concat([metrics_ds[dataset_name], mean_metrics_df, std_metrics_df], axis=1)\n",
    "        else:\n",
    "            metrics_ds[dataset_name] = pd.concat([mean_metrics_df, std_metrics_df], axis=1)\n"
   ],
   "id": "ff30a406fd093174",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T12:55:15.188922Z",
     "start_time": "2025-08-10T12:55:15.107911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(generate_latex_table_from_dataframe(metrics_ds['amazon-beauty'],\n",
    "                                          'Models performance over test split of amazon-beauty dataset.',\n",
    "                                          \"tab:amazon-beauty-ranking\", columns))\n",
    "\n",
    "print(generate_latex_table_from_dataframe(metrics_ds['ml-1m'], 'Models performance over test split of ml-1m dataset.', \"tab:ml-1m-ranking\", columns))\n",
    "\n",
    "print(generate_latex_table_from_dataframe(metrics_ds['jester-joke'], 'Metrics of the models in test split of jester-joke.',\"tab:jester-joke-ranking\", columns))\n",
    "\n",
    "print(generate_latex_table_from_dataframe(metrics_ds['rotten-tomatoes'], 'Metrics of the models in test split of rotten-tomatoes.',\"tab:rotten-tomatoes-ranking\", columns))\n"
   ],
   "id": "529b1a417795c2ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Models performance over test split of amazon-beauty dataset.}\n",
      "\\label{tab:amazon-beauty-ranking}\n",
      "\\begin{tabular}{cccccccccc}\n",
      "\\toprule\n",
      "metric & learn-rank-cpgatbpr & learn-rank-cpmfbpr & learn-rank-dgatbpr & learn-rank-mf & learn-rank-att-cluster \\\\\n",
      "\\midrule\n",
      "rmse & \\textbf{0.7927} $ \\pm $ 0.0638 & 0.8394 $ \\pm $ 0.0126 & 1.4036 $ \\pm $ 0.095 & 3.0199 $ \\pm $ 0.1178 & 2.0493 $ \\pm $ 0.4067 \\\\\n",
      "mae & \\textbf{0.6436} $ \\pm $ 0.0333 & 0.7644 $ \\pm $ 0.0141 & 1.1463 $ \\pm $ 0.0652 & 2.424 $ \\pm $ 0.0944 & 1.642 $ \\pm $ 0.4103 \\\\\n",
      "mNDCG@10 & 0.5128 $ \\pm $ 0.0183 & 0.6338 $ \\pm $ 0.0142 & 0.5301 $ \\pm $ 0.0157 & \\textbf{0.6378} $ \\pm $ 0.0081 & 0.6015 $ \\pm $ 0.025 \\\\\n",
      "mAP@10 & 0.4894 $ \\pm $ 0.0239 & \\textbf{0.6616} $ \\pm $ 0.0139 & 0.5111 $ \\pm $ 0.0256 & 0.6022 $ \\pm $ 0.014 & 0.5884 $ \\pm $ 0.037 \\\\\n",
      "mRecall@10 & 0.5045 $ \\pm $ 0.035 & \\textbf{0.7841} $ \\pm $ 0.0214 & 0.5236 $ \\pm $ 0.0426 & 0.6105 $ \\pm $ 0.0199 & 0.6055 $ \\pm $ 0.1249 \\\\\n",
      "MRR@10 & 0.7752 $ \\pm $ 0.0397 & 0.8469 $ \\pm $ 0.0114 & 0.7705 $ \\pm $ 0.0175 & \\textbf{0.8583} $ \\pm $ 0.0289 & 0.8359 $ \\pm $ 0.0612 \\\\\n",
      "mNDCG@3 & 0.5933 $ \\pm $ 0.0353 & 0.7277 $ \\pm $ 0.0164 & 0.5916 $ \\pm $ 0.0184 & \\textbf{0.7291} $ \\pm $ 0.0108 & 0.7084 $ \\pm $ 0.0526 \\\\\n",
      "mAP@3 & 0.5803 $ \\pm $ 0.0362 & \\textbf{0.7424} $ \\pm $ 0.0161 & 0.5833 $ \\pm $ 0.0227 & 0.7197 $ \\pm $ 0.0093 & 0.7083 $ \\pm $ 0.0479 \\\\\n",
      "mRecall@3 & 0.5833 $ \\pm $ 0.0379 & \\textbf{0.7939} $ \\pm $ 0.0181 & 0.5818 $ \\pm $ 0.0223 & 0.7197 $ \\pm $ 0.0093 & 0.5939 $ \\pm $ 0.1872 \\\\\n",
      "MRR@3 & 0.7583 $ \\pm $ 0.0426 & 0.8333 $ \\pm $ 0.011 & 0.7515 $ \\pm $ 0.0198 & \\textbf{0.8485} $ \\pm $ 0.0271 & 0.8182 $ \\pm $ 0.069 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}\n",
      "\\caption{Models performance over test split of ml-1m dataset.}\n",
      "\\label{tab:ml-1m-ranking}\n",
      "\\begin{tabular}{cccccccccc}\n",
      "\\toprule\n",
      "metric & learn-rank-cpgatbpr & learn-rank-cpmfbpr & learn-rank-dgatbpr & learn-rank-mf & learn-rank-att-cluster \\\\\n",
      "\\midrule\n",
      "rmse & 1.6175 $ \\pm $ 0.2054 & \\textbf{0.5951} $ \\pm $ 0.0682 & 4.1596 $ \\pm $ 2.0304 & 1.8068 $ \\pm $ 0.1698 & 1.6684 $ \\pm $ 0.1305 \\\\\n",
      "mae & 1.3041 $ \\pm $ 0.1095 & \\textbf{0.4955} $ \\pm $ 0.0623 & 3.1892 $ \\pm $ 1.6126 & 1.5092 $ \\pm $ 0.1617 & 1.3251 $ \\pm $ 0.1246 \\\\\n",
      "mNDCG@10 & \\textbf{0.9296} $ \\pm $ 0.0272 & 0.7563 $ \\pm $ 0.0879 & 0.8647 $ \\pm $ 0.1854 & 0.7635 $ \\pm $ 0.0919 & 0.7442 $ \\pm $ 0.1115 \\\\\n",
      "mAP@10 & \\textbf{0.9192} $ \\pm $ 0.016 & 0.7518 $ \\pm $ 0.0805 & 0.8613 $ \\pm $ 0.1703 & 0.7362 $ \\pm $ 0.0828 & 0.7192 $ \\pm $ 0.0993 \\\\\n",
      "mRecall@10 & \\textbf{0.9136} $ \\pm $ 0.0223 & 0.6358 $ \\pm $ 0.045 & 0.8573 $ \\pm $ 0.1673 & 0.7362 $ \\pm $ 0.0828 & 0.7186 $ \\pm $ 0.0902 \\\\\n",
      "MRR@10 & \\textbf{0.9986} $ \\pm $ 0.0029 & 0.9089 $ \\pm $ 0.0743 & 0.9315 $ \\pm $ 0.1526 & 0.9139 $ \\pm $ 0.078 & 0.9033 $ \\pm $ 0.0922 \\\\\n",
      "mNDCG@3 & \\textbf{0.9934} $ \\pm $ 0.0078 & 0.8212 $ \\pm $ 0.1054 & 0.8922 $ \\pm $ 0.236 & 0.8301 $ \\pm $ 0.1143 & 0.8136 $ \\pm $ 0.128 \\\\\n",
      "mAP@3 & \\textbf{0.993} $ \\pm $ 0.0067 & 0.8216 $ \\pm $ 0.1011 & 0.8916 $ \\pm $ 0.2367 & 0.8244 $ \\pm $ 0.1118 & 0.8077 $ \\pm $ 0.1249 \\\\\n",
      "mRecall@3 & \\textbf{0.9928} $ \\pm $ 0.0072 & 0.7677 $ \\pm $ 0.0883 & 0.8915 $ \\pm $ 0.2366 & 0.8244 $ \\pm $ 0.1118 & 0.8054 $ \\pm $ 0.1267 \\\\\n",
      "MRR@3 & \\textbf{0.9985} $ \\pm $ 0.0031 & 0.9049 $ \\pm $ 0.0807 & 0.9246 $ \\pm $ 0.168 & 0.9098 $ \\pm $ 0.0856 & 0.8982 $ \\pm $ 0.102 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}\n",
      "\\caption{Metrics of the models in test split of jester-joke.}\n",
      "\\label{tab:jester-joke-ranking}\n",
      "\\begin{tabular}{cccccccccc}\n",
      "\\toprule\n",
      "metric & learn-rank-cpgatbpr & learn-rank-cpmfbpr & learn-rank-dgatbpr & learn-rank-mf & learn-rank-att-cluster \\\\\n",
      "\\midrule\n",
      "rmse & 1.1631 $ \\pm $ 0.2411 & \\textbf{1.0511} $ \\pm $ 0.0036 & 1.6483 $ \\pm $ 0.5134 & 1.1134 $ \\pm $ 0.0095 & 1.2242 $ \\pm $ 0.2309 \\\\\n",
      "mae & 1.1583 $ \\pm $ 0.2398 & \\textbf{1.0439} $ \\pm $ 0.0032 & 1.5527 $ \\pm $ 0.3968 & 1.0766 $ \\pm $ 0.0077 & 1.1271 $ \\pm $ 0.2168 \\\\\n",
      "mNDCG@10 & 0.3588 $ \\pm $ 0.0673 & 0.5243 $ \\pm $ 0.008 & 0.3494 $ \\pm $ 0.0284 & \\textbf{0.5402} $ \\pm $ 0.0039 & 0.4926 $ \\pm $ 0.0155 \\\\\n",
      "mAP@10 & 0.3529 $ \\pm $ 0.0582 & 0.5148 $ \\pm $ 0.0065 & 0.3534 $ \\pm $ 0.0237 & \\textbf{0.5324} $ \\pm $ 0.0045 & 0.4932 $ \\pm $ 0.0224 \\\\\n",
      "mRecall@10 & \\textbf{0.6471} $ \\pm $ 0.0582 & 0.4852 $ \\pm $ 0.0065 & 0.6409 $ \\pm $ 0.0327 & 0.4689 $ \\pm $ 0.0037 & 0.5169 $ \\pm $ 0.0022 \\\\\n",
      "MRR@10 & 0.5495 $ \\pm $ 0.0876 & 0.7132 $ \\pm $ 0.0361 & 0.5353 $ \\pm $ 0.054 & \\textbf{0.7137} $ \\pm $ 0.0223 & 0.678 $ \\pm $ 0.0312 \\\\\n",
      "mNDCG@3 & 0.3757 $ \\pm $ 0.1039 & 0.5502 $ \\pm $ 0.0282 & 0.3558 $ \\pm $ 0.0595 & \\textbf{0.5621} $ \\pm $ 0.0095 & 0.5196 $ \\pm $ 0.0313 \\\\\n",
      "mAP@3 & 0.3795 $ \\pm $ 0.1122 & 0.5528 $ \\pm $ 0.0233 & 0.3662 $ \\pm $ 0.0673 & \\textbf{0.5721} $ \\pm $ 0.0087 & 0.5336 $ \\pm $ 0.0347 \\\\\n",
      "mRecall@3 & \\textbf{0.6205} $ \\pm $ 0.1122 & 0.4472 $ \\pm $ 0.0233 & 0.6113 $ \\pm $ 0.109 & 0.4277 $ \\pm $ 0.01 & 0.479 $ \\pm $ 0.0165 \\\\\n",
      "MRR@3 & 0.5092 $ \\pm $ 0.1136 & 0.6903 $ \\pm $ 0.0416 & 0.4887 $ \\pm $ 0.0682 & \\textbf{0.6908} $ \\pm $ 0.0287 & 0.6503 $ \\pm $ 0.0387 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}\n",
      "\\caption{Metrics of the models in test split of rotten-tomatoes.}\n",
      "\\label{tab:rotten-tomatoes-ranking}\n",
      "\\begin{tabular}{cccccccccc}\n",
      "\\toprule\n",
      "metric & learn-rank-cpgatbpr & learn-rank-cpmfbpr & learn-rank-dgatbpr & learn-rank-mf & learn-rank-att-cluster \\\\\n",
      "\\midrule\n",
      "rmse & 1.0215 $ \\pm $ 0.0742 & \\textbf{0.6598} $ \\pm $ 0.0053 & 1.9477 $ \\pm $ 0.2984 & 1.6299 $ \\pm $ 0.12 & 1.8695 $ \\pm $ 0.1153 \\\\\n",
      "mae & 0.892 $ \\pm $ 0.0567 & \\textbf{0.5474} $ \\pm $ 0.0062 & 1.6187 $ \\pm $ 0.1933 & 1.3333 $ \\pm $ 0.0987 & 1.492 $ \\pm $ 0.113 \\\\\n",
      "mNDCG@10 & \\textbf{0.7848} $ \\pm $ 0.0337 & 0.7287 $ \\pm $ 0.0033 & 0.7615 $ \\pm $ 0.0267 & 0.7391 $ \\pm $ 0.0097 & 0.729 $ \\pm $ 0.0102 \\\\\n",
      "mAP@10 & \\textbf{0.7939} $ \\pm $ 0.0487 & 0.7245 $ \\pm $ 0.003 & 0.7469 $ \\pm $ 0.0422 & 0.7164 $ \\pm $ 0.0072 & 0.7174 $ \\pm $ 0.0092 \\\\\n",
      "mRecall@10 & \\textbf{0.7759} $ \\pm $ 0.0167 & 0.6777 $ \\pm $ 0.0073 & 0.7692 $ \\pm $ 0.0188 & 0.7165 $ \\pm $ 0.0072 & 0.6772 $ \\pm $ 0.0299 \\\\\n",
      "MRR@10 & \\textbf{0.9618} $ \\pm $ 0.0148 & 0.8861 $ \\pm $ 0.012 & 0.9458 $ \\pm $ 0.0109 & 0.8889 $ \\pm $ 0.01 & 0.8963 $ \\pm $ 0.0094 \\\\\n",
      "mNDCG@3 & \\textbf{0.9036} $ \\pm $ 0.0261 & 0.7914 $ \\pm $ 0.0143 & 0.881 $ \\pm $ 0.0225 & 0.7947 $ \\pm $ 0.0174 & 0.7936 $ \\pm $ 0.0073 \\\\\n",
      "mAP@3 & \\textbf{0.9012} $ \\pm $ 0.0291 & 0.7968 $ \\pm $ 0.015 & 0.8744 $ \\pm $ 0.0248 & 0.7906 $ \\pm $ 0.0176 & 0.7934 $ \\pm $ 0.0057 \\\\\n",
      "mRecall@3 & \\textbf{0.8916} $ \\pm $ 0.0125 & 0.7637 $ \\pm $ 0.0072 & 0.8853 $ \\pm $ 0.0187 & 0.7906 $ \\pm $ 0.0176 & 0.7606 $ \\pm $ 0.0302 \\\\\n",
      "MRR@3 & \\textbf{0.9585} $ \\pm $ 0.0154 & 0.8793 $ \\pm $ 0.0134 & 0.9416 $ \\pm $ 0.0116 & 0.8824 $ \\pm $ 0.0121 & 0.8899 $ \\pm $ 0.0105 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T12:55:15.220390Z",
     "start_time": "2025-08-10T12:55:15.216990Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d888294f30c0e71e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
